GNU 13.2.0 is now loaded
Loading module for CUDA 11.8
CUDA 11.8 is now loaded
Loading module for Machine Learning 2024.01
Machine Learning 2024.01 is now loaded

Loading machine_learning/2024.01
  Loading requirement: gcc/13.2.0 cuda/11.8
Loading module for pytorch 2.0
pytorch 2.0 is now loaded
Dataset mean: 0.1799, std: 0.7484
Epoch [1/100] - SupCon Loss: 2.1738
Epoch [2/100] - SupCon Loss: 1.7921
Epoch [3/100] - SupCon Loss: 1.6905
Epoch [4/100] - SupCon Loss: 1.6336
Epoch [5/100] - SupCon Loss: 1.5874
Epoch [6/100] - SupCon Loss: 1.5613
Epoch [7/100] - SupCon Loss: 1.5299
Epoch [8/100] - SupCon Loss: 1.5042
Epoch [9/100] - SupCon Loss: 1.4794
Epoch [10/100] - SupCon Loss: 1.4769
Epoch [11/100] - SupCon Loss: 1.4484
Epoch [12/100] - SupCon Loss: 1.4359
Epoch [13/100] - SupCon Loss: 1.4262
Epoch [14/100] - SupCon Loss: 1.4302
Epoch [15/100] - SupCon Loss: 1.4107
Epoch [16/100] - SupCon Loss: 1.3978
Epoch [17/100] - SupCon Loss: 1.3866
Epoch [18/100] - SupCon Loss: 1.3816
Epoch [19/100] - SupCon Loss: 1.3752
Epoch [20/100] - SupCon Loss: 1.3713
Epoch [21/100] - SupCon Loss: 1.3628
Epoch [22/100] - SupCon Loss: 1.3593
Epoch [23/100] - SupCon Loss: 1.3454
Epoch [24/100] - SupCon Loss: 1.3518
Epoch [25/100] - SupCon Loss: 1.3352
Epoch [26/100] - SupCon Loss: 1.3332
Epoch [27/100] - SupCon Loss: 1.3194
Epoch [28/100] - SupCon Loss: 1.3237
Epoch [29/100] - SupCon Loss: 1.3145
Epoch [30/100] - SupCon Loss: 1.3085
Epoch [31/100] - SupCon Loss: 1.3056
Epoch [32/100] - SupCon Loss: 1.3022
Epoch [33/100] - SupCon Loss: 1.2923
Epoch [34/100] - SupCon Loss: 1.2882
Epoch [35/100] - SupCon Loss: 1.2857
Epoch [36/100] - SupCon Loss: 1.2846
Epoch [37/100] - SupCon Loss: 1.2732
Epoch [38/100] - SupCon Loss: 1.2696
Epoch [39/100] - SupCon Loss: 1.2645
Epoch [40/100] - SupCon Loss: 1.2656
Epoch [41/100] - SupCon Loss: 1.2515
Epoch [42/100] - SupCon Loss: 1.2562
Epoch [43/100] - SupCon Loss: 1.2522
Epoch [44/100] - SupCon Loss: 1.2421
Epoch [45/100] - SupCon Loss: 1.2398
Epoch [46/100] - SupCon Loss: 1.2299
Epoch [47/100] - SupCon Loss: 1.2362
Epoch [48/100] - SupCon Loss: 1.2303
Epoch [49/100] - SupCon Loss: 1.2222
Epoch [50/100] - SupCon Loss: 1.2114
Epoch [51/100] - SupCon Loss: 1.2171
Epoch [52/100] - SupCon Loss: 1.2168
Epoch [53/100] - SupCon Loss: 1.2005
Epoch [54/100] - SupCon Loss: 1.1967
Epoch [55/100] - SupCon Loss: 1.1888
Epoch [56/100] - SupCon Loss: 1.1875
Epoch [57/100] - SupCon Loss: 1.1793
Epoch [58/100] - SupCon Loss: 1.1782
Epoch [59/100] - SupCon Loss: 1.1745
Epoch [60/100] - SupCon Loss: 1.1651
Epoch [61/100] - SupCon Loss: 1.1726
Epoch [62/100] - SupCon Loss: 1.1675
Epoch [63/100] - SupCon Loss: 1.1536
Epoch [64/100] - SupCon Loss: 1.1514
Epoch [65/100] - SupCon Loss: 1.1472
Epoch [66/100] - SupCon Loss: 1.1483
Epoch [67/100] - SupCon Loss: 1.1474
Epoch [68/100] - SupCon Loss: 1.1307
Epoch [69/100] - SupCon Loss: 1.1220
Epoch [70/100] - SupCon Loss: 1.1345
Epoch [71/100] - SupCon Loss: 1.1319
Epoch [72/100] - SupCon Loss: 1.1190
Epoch [73/100] - SupCon Loss: 1.1138
Epoch [74/100] - SupCon Loss: 1.1077
Epoch [75/100] - SupCon Loss: 1.1096
Epoch [76/100] - SupCon Loss: 1.1098
Epoch [77/100] - SupCon Loss: 1.1019
Epoch [78/100] - SupCon Loss: 1.1074
Epoch [79/100] - SupCon Loss: 1.0893
Epoch [80/100] - SupCon Loss: 1.0937
Epoch [81/100] - SupCon Loss: 1.0878
Epoch [82/100] - SupCon Loss: 1.0837
Epoch [83/100] - SupCon Loss: 1.0866
Epoch [84/100] - SupCon Loss: 1.0771
Epoch [85/100] - SupCon Loss: 1.0769
Epoch [86/100] - SupCon Loss: 1.0755
Epoch [87/100] - SupCon Loss: 1.0767
Epoch [88/100] - SupCon Loss: 1.0663
Epoch [89/100] - SupCon Loss: 1.0739
Epoch [90/100] - SupCon Loss: 1.0543
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** STEP 40125677.0 ON gpu502-11 CANCELLED AT 2025-08-08T11:58:03 ***
/sw/rl9g/pytorch-2.0/conda3env/env/lib/python3.8/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.elastic.agent.server.api:Received 15 death signal, shutting down workers
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 1121259 closing signal SIGTERM
slurmstepd: error: *** JOB 40125677 ON gpu502-11 CANCELLED AT 2025-08-08T11:58:03 ***
