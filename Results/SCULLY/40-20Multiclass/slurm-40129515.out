GNU 13.2.0 is now loaded
Loading module for CUDA 11.8
CUDA 11.8 is now loaded
Loading module for Machine Learning 2024.01
Machine Learning 2024.01 is now loaded

Loading machine_learning/2024.01
  Loading requirement: gcc/13.2.0 cuda/11.8
Loading module for pytorch 2.0
pytorch 2.0 is now loaded
Dataset mean: 0.1799, std: 0.7484
Epoch [1/40] - SupCon Loss: 2.1738
Epoch [2/40] - SupCon Loss: 1.7887
Epoch [3/40] - SupCon Loss: 1.6964
Epoch [4/40] - SupCon Loss: 1.6454
Epoch [5/40] - SupCon Loss: 1.5876
Epoch [6/40] - SupCon Loss: 1.5600
Epoch [7/40] - SupCon Loss: 1.5341
Epoch [8/40] - SupCon Loss: 1.5082
Epoch [9/40] - SupCon Loss: 1.4922
Epoch [10/40] - SupCon Loss: 1.4763
Epoch [11/40] - SupCon Loss: 1.4536
Epoch [12/40] - SupCon Loss: 1.4411
Epoch [13/40] - SupCon Loss: 1.4330
Epoch [14/40] - SupCon Loss: 1.4188
Epoch [15/40] - SupCon Loss: 1.4100
Epoch [16/40] - SupCon Loss: 1.4008
Epoch [17/40] - SupCon Loss: 1.4008
Epoch [18/40] - SupCon Loss: 1.3940
Epoch [19/40] - SupCon Loss: 1.3811
Epoch [20/40] - SupCon Loss: 1.3632
Epoch [21/40] - SupCon Loss: 1.3687
Epoch [22/40] - SupCon Loss: 1.3522
Epoch [23/40] - SupCon Loss: 1.3524
Epoch [24/40] - SupCon Loss: 1.3499
Epoch [25/40] - SupCon Loss: 1.3502
Epoch [26/40] - SupCon Loss: 1.3381
Epoch [27/40] - SupCon Loss: 1.3341
Epoch [28/40] - SupCon Loss: 1.3228
Epoch [29/40] - SupCon Loss: 1.3110
Epoch [30/40] - SupCon Loss: 1.3128
Epoch [31/40] - SupCon Loss: 1.3074
Epoch [32/40] - SupCon Loss: 1.2957
Epoch [33/40] - SupCon Loss: 1.3028
Epoch [34/40] - SupCon Loss: 1.2828
Epoch [35/40] - SupCon Loss: 1.2914
Epoch [36/40] - SupCon Loss: 1.2749
Epoch [37/40] - SupCon Loss: 1.2721
Epoch [38/40] - SupCon Loss: 1.2686
Epoch [39/40] - SupCon Loss: 1.2685
Epoch [40/40] - SupCon Loss: 1.2616
Class counts: [1276, 1357, 2157, 975, 991, 1773, 1521, 1513, 2038, 1149, 1083, 1912, 1365, 1623, 1104, 1152, 1505, 1490, 1632, 1882, 609, 913, 2518, 1807, 2209, 2121, 1331, 1171, 1593, 1850, 673, 1600, 896, 1551, 2275, 1705, 1240]
Epoch 1/20, Loss: 0.5774
F1 Score: 0.7571
Epoch 2/20, Loss: 0.4132
F1 Score: 0.7583
Epoch 3/20, Loss: 0.3915
F1 Score: 0.7689
Epoch 4/20, Loss: 0.3792
F1 Score: 0.7653
Epoch 5/20, Loss: 0.3674
F1 Score: 0.7628
Epoch 6/20, Loss: 0.3612
F1 Score: 0.7677
Epoch 7/20, Loss: 0.3524
F1 Score: 0.7661
Epoch 8/20, Loss: 0.3474
F1 Score: 0.7621
Epoch 9/20, Loss: 0.3425
F1 Score: 0.7661
Epoch 10/20, Loss: 0.3365
F1 Score: 0.7625
Epoch 11/20, Loss: 0.3310
F1 Score: 0.7681
Epoch 12/20, Loss: 0.3276
F1 Score: 0.7635
Epoch 13/20, Loss: 0.3263
F1 Score: 0.7712
Epoch 14/20, Loss: 0.3193
F1 Score: 0.7661
Epoch 15/20, Loss: 0.3157
F1 Score: 0.7691
Epoch 16/20, Loss: 0.3147
F1 Score: 0.7672
Epoch 17/20, Loss: 0.3110
F1 Score: 0.7714
Epoch 18/20, Loss: 0.3075
F1 Score: 0.7658
Epoch 19/20, Loss: 0.3067
F1 Score: 0.7673
Epoch 20/20, Loss: 0.3040
F1 Score: 0.7699
Validation Performance:
F1 Score: 0.7699
Test Performance:
F1 Score: 0.7670
/sw/rl9g/pytorch-2.0/conda3env/env/lib/python3.8/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
